{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "disp_freq = 100\n",
    "\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y_ = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "# Create model\n",
    "def conv_net(x, weights, biases):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "def norm(l_input, lsize=4):\n",
    "    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "def alex_net(x,weights,biases):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    conv1 = norm(conv1,lsize=4) \n",
    "    \n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    conv2 = norm(conv2,lsize=4)\n",
    "    \n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    conv3 = maxpool2d(conv3,k=2)\n",
    "    conv3 = norm(conv3,lsize=4)\n",
    "    \n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]]) \n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc2 = tf.nn.relu(tf.matmul(fc1, weights['wd2']) + biases['bd2']) \n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "    return out\n",
    "    \n",
    "class Model:\n",
    "\n",
    "\n",
    "    def __init__(self, x, y_):\n",
    "\n",
    "        self.x = x # input placeholder\n",
    "    \n",
    "        weights = {\n",
    "        'wc1': tf.Variable(tf.truncated_normal([3, 3, 1, 64],stddev=0.001)),\n",
    "        'wc2': tf.Variable(tf.truncated_normal([3, 3, 64, 128],stddev=0.001)),\n",
    "        'wc3': tf.Variable(tf.truncated_normal([3, 3, 128, 256],stddev=0.001)),\n",
    "        'wd1': tf.Variable(tf.truncated_normal([4*4*256, 1024],stddev=0.001)),\n",
    "        'wd2': tf.Variable(tf.truncated_normal([1024, 1024],stddev=0.001)),\n",
    "        'out': tf.Variable(tf.truncated_normal([1024, 10],stddev=0.001))\n",
    "        }\n",
    "        biases = {\n",
    "        'bc1': tf.Variable(tf.truncated_normal([64],stddev=0.001)),\n",
    "        'bc2': tf.Variable(tf.truncated_normal([128],stddev=0.001)),\n",
    "        'bc3': tf.Variable(tf.truncated_normal([256],stddev=0.001)),\n",
    "        'bd1': tf.Variable(tf.truncated_normal([1024],stddev=0.001)),\n",
    "        'bd2': tf.Variable(tf.truncated_normal([1024],stddev=0.001)),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_classes],stddev=0.001))\n",
    "        }\n",
    "        \n",
    "        self.y = alex_net(x, weights, biases)\n",
    "        self.var_list=[weights['wc1'],weights['wc2'],weights['wc3'],weights['wd1'],weights['wd2'],weights['out'],\n",
    "                       biases['bc1'],biases['bc2'],biases['bc3'],biases['bd1'],biases['bd2'],biases['out']]\n",
    "#         weights = {\n",
    "#         # 5x5 conv, 1 input, 32 outputs\n",
    "#         'wc1': tf.Variable(tf.truncated_normal([5, 5, 1, 32],stddev=0.001)),\n",
    "#         # 5x5 conv, 32 inputs, 64 outputs\n",
    "#         'wc2': tf.Variable(tf.truncated_normal([5, 5, 32, 64],stddev=0.001)),\n",
    "#         # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "#         'wd1': tf.Variable(tf.truncated_normal([7*7*64, 1024],stddev=0.001)),\n",
    "#         # 1024 inputs, 10 outputs (class prediction)\n",
    "#         'out': tf.Variable(tf.truncated_normal([1024, n_classes],stddev=0.001))\n",
    "#         }\n",
    "\n",
    "#         biases = {\n",
    "#         'bc1': tf.Variable(tf.truncated_normal([32],stddev=0.001)),\n",
    "#         'bc2': tf.Variable(tf.truncated_normal([64],stddev=0.001)),\n",
    "#         'bd1': tf.Variable(tf.truncated_normal([1024],stddev=0.001)),\n",
    "#         'out': tf.Variable(tf.truncated_normal([n_classes],stddev=0.001))\n",
    "#         }\n",
    "       \n",
    "        \n",
    "#         self.y = conv_net(x, weights, biases)\n",
    "\n",
    "#         self.var_list=[weights['wc1'],weights['wc2'],weights['wd1'],weights['out'],\n",
    "#                        biases['bc1'],biases['bc2'],biases['bd1'],biases['out']]\n",
    "\n",
    "        # simple 2-layer network\n",
    "#         in_dim = int(x.get_shape()[1]) # 784 for MNIST\n",
    "#         out_dim = int(y_.get_shape()[1]) # 10 for MNIST\n",
    "\n",
    "#         W1 = weight_variable([in_dim,50])\n",
    "#         b1 = bias_variable([50])\n",
    "\n",
    "#         W2 = weight_variable([50,out_dim])\n",
    "#         b2 = bias_variable([out_dim])\n",
    "\n",
    "#         h1 = tf.nn.relu(tf.matmul(x,W1) + b1) # hidden layer    \n",
    "#         self.y = tf.matmul(h1,W2) + b2\n",
    "#         self.var_list = [W1, b1, W2, b2]\n",
    "        \n",
    "        \n",
    "        self.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.y,labels=y_))\n",
    "\n",
    "        self.set_vanilla_loss()\n",
    "        \n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.y,1), tf.argmax(y_,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "\n",
    "    def compute_fisher(self, imgset, sess, num_samples=200, plot_diffs=False, disp_freq=10):\n",
    "        # compute Fisher information for each parameter\n",
    "\n",
    "        # initialize Fisher information for most recent task\n",
    "        self.F_accum = []\n",
    "        for v in range(len(self.var_list)):\n",
    "            self.F_accum.append(np.zeros(self.var_list[v].get_shape().as_list()))\n",
    "\n",
    "        # sampling a random class from softmax\n",
    "        probs = tf.nn.softmax(self.y)\n",
    "        class_ind = tf.to_int32(tf.multinomial(tf.log(probs), 1)[0][0])\n",
    "\n",
    "        if(plot_diffs):\n",
    "            # track differences in mean Fisher info\n",
    "            F_prev = deepcopy(self.F_accum)\n",
    "            mean_diffs = np.zeros(0)\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            # select random input image\n",
    "            im_ind = np.random.randint(imgset.shape[0])\n",
    "            # compute first-order derivatives\n",
    "            ders = sess.run(tf.gradients(tf.log(probs[0,class_ind]), self.var_list), feed_dict={self.x: imgset[im_ind:im_ind+1]})\n",
    "            # square the derivatives and add to total\n",
    "            for v in range(len(self.F_accum)):\n",
    "                self.F_accum[v] += np.square(ders[v])\n",
    "            if(plot_diffs):\n",
    "                if i % disp_freq == 0 and i > 0:\n",
    "                    # recording mean diffs of F\n",
    "                    F_diff = 0\n",
    "                    for v in range(len(self.F_accum)):\n",
    "                        F_diff += np.sum(np.absolute(self.F_accum[v]/(i+1) - F_prev[v]))\n",
    "                    mean_diff = np.mean(F_diff)\n",
    "                    mean_diffs = np.append(mean_diffs, mean_diff)\n",
    "                    for v in range(len(self.F_accum)):\n",
    "                        F_prev[v] = self.F_accum[v]/(i+1)\n",
    "                    plt.plot(range(disp_freq+1, i+2, disp_freq), mean_diffs)\n",
    "                    plt.xlabel(\"Number of samples\")\n",
    "                    plt.ylabel(\"Mean absolute Fisher difference\")\n",
    "                    display.display(plt.gcf())\n",
    "                    display.clear_output(wait=True)\n",
    "\n",
    "        # divide totals by number of samples\n",
    "        for v in range(len(self.F_accum)):\n",
    "            self.F_accum[v] /= num_samples\n",
    "    \n",
    "    def set_vanilla_loss(self):\n",
    "        self.train_step = tf.train.AdamOptimizer(0.001).minimize(self.cross_entropy)\n",
    "\n",
    "    def star(self):\n",
    "    # used for saving optimal weights after most recent task training\n",
    "        self.star_vars = []\n",
    "        for v in range(len(self.var_list)):\n",
    "            self.star_vars.append(self.var_list[v].eval())\n",
    "    def update_ewc_loss(self, lam):\n",
    "        # elastic weight consolidation\n",
    "        # lam is weighting for previous task(s) constraints\n",
    "\n",
    "        if not hasattr(self, \"ewc_loss\"):\n",
    "            self.ewc_loss = self.cross_entropy\n",
    "\n",
    "        for v in range(len(self.var_list)):\n",
    "            self.ewc_loss += (lam/2) * tf.reduce_sum(tf.multiply(self.F_accum[v].astype(np.float32),tf.square(self.var_list[v] - self.star_vars[v])))\n",
    "        self.train_step = tf.train.AdamOptimizer(0.001).minimize(self.ewc_loss)\n",
    "    def restore(self, sess):\n",
    "    # reassign optimal weights for latest task\n",
    "        if hasattr(self, \"star_vars\"):\n",
    "            for v in range(len(self.var_list)):\n",
    "                sess.run(self.var_list[v].assign(self.star_vars[v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with tf.device('/gpu:0'):\n",
    "model = Model(x, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist_imshow(img):\n",
    "    plt.imshow(img.reshape([28,28]), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "def permute_mnist(mnist):\n",
    "    perm_inds = range(mnist.train.images.shape[1])\n",
    "    np.random.shuffle(perm_inds)\n",
    "    mnist2 = deepcopy(mnist)\n",
    "    sets = [\"train\", \"validation\", \"test\"]\n",
    "    for set_name in sets:\n",
    "        this_set = getattr(mnist2, set_name) # shallow copy\n",
    "        this_set._images = np.transpose(np.array([this_set.images[:,c] for c in perm_inds]))\n",
    "    return mnist2\n",
    "\n",
    "def plot_test_acc(plot_handles):\n",
    "    plt.legend(handles=plot_handles, loc=\"center right\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.ylim(0,1)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_task(model, num_iter, disp_freq,sess, trainset, testsets, x, y_, lams=[0]):\n",
    "    for l in range(len(lams)):\n",
    "        # lams[l] sets weight on old task(s)\n",
    "        temp = set(tf.global_variables())\n",
    "        model.restore(sess) # reassign optimal weights from previous training session\n",
    "        if(lams[l] == 0):\n",
    "            model.set_vanilla_loss()\n",
    "        else:\n",
    "            model.update_ewc_loss(lams[l])\n",
    "            #model.train_step = tf.train.AdamOptimizer(0.01).minimize(model.ewc_loss)\n",
    "        # initialize test accuracy array for each task \n",
    "        #Optimizer = tf.train.AdamOptimizer(0.01).minimize(model.ewc_loss)\n",
    "        sess.run(tf.variables_initializer(set(tf.global_variables()) - temp))\n",
    "        \n",
    "        test_accs = []\n",
    "        for task in range(len(testsets)):\n",
    "            test_accs.append(np.zeros(num_iter/disp_freq))\n",
    "        # train on current task\n",
    "        step = 0\n",
    "        for iter in range(num_iter):\n",
    "            batch = trainset.train.next_batch(batch_size)\n",
    "            model.train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "            #print model.prediction.eval(feed_dict={x: mnist.test.images})\n",
    "            if (iter % disp_freq == 0):\n",
    "                plt.subplot(1, len(lams), l+1)\n",
    "                plots = []\n",
    "                colors = ['r', 'b', 'g']\n",
    "                for task in range(len(testsets)):\n",
    "                    feed_dict={x: testsets[task].test.images, y_: testsets[task].test.labels}\n",
    "                    test_accs[task][iter/disp_freq] = model.accuracy.eval(feed_dict=feed_dict)\n",
    "                    c = chr(ord('A') + task)\n",
    "                    plot_h, = plt.plot(range(1,iter+2,disp_freq), test_accs[task][:iter/disp_freq+1], colors[task], label=\"task \" + c)\n",
    "                    plots.append(plot_h)\n",
    "                plot_test_acc(plots)\n",
    "                if l == 0: \n",
    "                    plt.title(\"Cross Entropy\")\n",
    "                else:\n",
    "                    plt.title(\"ewc\")\n",
    "                plt.gcf().set_size_inches(len(lams)*5, 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD7CAYAAADuFMYYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4NA0M8vBoWlmlsP/AP4Spw6RpFLkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11b35af490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = tf.ConfigProto() \n",
    "config.gpu_options.allow_growth=True \n",
    "config.log_device_placement=True\n",
    "sess = tf.InteractiveSession()#(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_task(model, 1000, 100, sess, mnist, [mnist], x, y_, lams=[0])\n",
    "#train_task_separate(model, 1300, 100, sess, mnist,1, [mnist], x, y_, lams=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_fisher(mnist.validation.images, sess, num_samples=200, plot_diffs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist2 = permute_mnist(mnist)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "mnist_imshow(mnist.train.images[5])\n",
    "plt.title(\"original task image\")\n",
    "plt.subplot(1,2,2)\n",
    "mnist_imshow(mnist2.train.images[5])\n",
    "plt.title(\"new task image\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.star()\n",
    "train_task(model, 1000, 100,sess, mnist2, [mnist, mnist2], x, y_, lams=[0, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpu():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_available_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < 130000:\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        # 获取批数据\n",
    "        model.train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "        if step % 100 == 0:\n",
    "            # 计算精度\n",
    "            feed_dict={x: mnist.test.images, y_: mnist.test.labels}\n",
    "            acc = model.accuracy.eval(feed_dict=feed_dict)\n",
    "            # 计算损失值\n",
    "            loss = model.cross_entropy.eval(feed_dict=feed_dict)\n",
    "            print (\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy = \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")\n",
    "    # 计算测试精度\n",
    "    print (\"Testing Accuracy:\",  model.accuracy.eval(feed_dict={x: mnist.test.images[:256], _y: mnist.test.labels[:256]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compute_fisher(mnist2.validation.images, sess, num_samples=200, plot_diffs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist3 = permute_mnist(mnist)\n",
    "model.star()\n",
    "train_task(model, 1300, 100,sess, mnist3, [mnist, mnist2, mnist3], x, y_, lams=[0, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
